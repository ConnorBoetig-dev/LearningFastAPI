name: Publish Comment-Free Mirror

on:
  push:
    branches: [ main ]
  workflow_dispatch: {}

jobs:
  build-and-sync:
    runs-on: ubuntu-latest

    env:
      DEST_OWNER: ConnorBoetig-dev
      DEST_REPO: LearningFastAPI-clean
      DEST_DEFAULT_BRANCH: main
      GIT_AUTHOR_NAME: "CI Mirror"
      GIT_AUTHOR_EMAIL: "ci@nowhere.local"
      GIT_COMMITTER_NAME: "CI Mirror"
      GIT_COMMITTER_EMAIL: "ci@nowhere.local"

    steps:
      - name: Checkout source (commented repo)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up Node (needed for parser-aware JS/TS/HTML/CSS stripping)
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install Python dependencies for comment stripping
        run: pip install pyyaml tomli_w -q

      - name: Copy project into clean/ (exclude CI and junk)
        run: |
          mkdir -p clean
          rsync -a \
            --exclude ".git" \
            --exclude ".github" \
            --exclude "node_modules" \
            --exclude ".venv" \
            --exclude "__pycache__" \
            --exclude "*.png" --exclude "*.jpg" --exclude "*.jpeg" --exclude "*.gif" \
            ./ ./clean/

      - name: Install strip-comments for web assets
        run: |
          npm init -y >/dev/null 2>&1
          npm i strip-comments -D >/dev/null 2>&1

      - name: Strip ALL comments (multi-language, parser-aware where possible)
        run: |
          python - <<'PY'
          # === Comment killer: removes ALL comments, including inline + docstrings ===
          import os, re, sys, subprocess, json, pathlib, io, tokenize, ast
          from pathlib import Path

          ROOT = Path("clean").resolve()

          def read_utf8(p):
              try: return p.read_text(encoding="utf-8")
              except Exception: return None

          def write_utf8(p, s):
              p.write_text(s.rstrip("\n") + "\n", encoding="utf-8")

          # Python: remove comments + docstrings
          def strip_python(code: str) -> str:
              out = []
              tok_gen = tokenize.generate_tokens(io.StringIO(code).readline)
              for tok_type, tok_str, start, end, line in tok_gen:
                  if tok_type == tokenize.COMMENT: continue
                  out.append((tok_type, tok_str, start, end, line))
              code_no_comments = tokenize.untokenize(out)
              try:
                  tree = ast.parse(code_no_comments)
              except Exception:
                  return code_no_comments
              class DocStrip(ast.NodeTransformer):
                  def strip_doc(self, node):
                      if node.body and isinstance(node.body[0], ast.Expr):
                          val = getattr(node.body[0], "value", None)
                          if isinstance(val, ast.Constant) and isinstance(val.value, str):
                              node.body.pop(0)
                      return node
                  def visit_FunctionDef(self, node): self.generic_visit(node); return self.strip_doc(node)
                  def visit_AsyncFunctionDef(self, node): self.generic_visit(node); return self.strip_doc(node)
                  def visit_ClassDef(self, node): self.generic_visit(node); return self.strip_doc(node)
                  def visit_Module(self, node): self.generic_visit(node); return self.strip_doc(node)
              tree = DocStrip().visit(tree)
              try: return ast.unparse(tree)
              except Exception: return code_no_comments

          # Shell/.env/Dockerfile
          def strip_hash_lang(code: str) -> str:
              out_lines = []
              for i, line in enumerate(code.splitlines()):
                  if i == 0 and line.startswith("#!"):
                      out_lines.append(line)
                      continue
                  s = []
                  in_s = in_d = False
                  for ch in line:
                      if ch == "'" and not in_d: in_s = not in_s; s.append(ch); continue
                      if ch == '"' and not in_s: in_d = not in_d; s.append(ch); continue
                      if ch == "#" and not in_s and not in_d: break
                      s.append(ch)
                  out_lines.append("".join(s).rstrip())
              return "\n".join(out_lines) + "\n"

          # SQL
          def strip_sql(code: str) -> str:
              out = []
              i = 0
              in_s = in_d = False
              in_block = False
              while i < len(code):
                  if in_block:
                      if code.startswith("*/", i):
                          in_block = False
                          i += 2
                      else:
                          i += 1
                      continue
                  ch = code[i]
                  nxt = code[i+1] if i+1 < len(code) else ""
                  if not in_s and not in_d:
                      if ch == "/" and nxt == "*":
                          in_block = True
                          i += 2
                          continue
                      if ch == "-" and nxt == "-":
                          i += 2
                          while i < len(code) and code[i] != "\n": i += 1
                          continue
                      if ch == "'": in_s = True
                      elif ch == '"': in_d = True
                  else:
                      if in_s and ch == "'" and nxt != "'": in_s = False
                      elif in_d and ch == '"' and nxt != '"': in_d = False
                  out.append(ch)
                  i += 1
              return "".join(out)

          # YAML/TOML/INI: reload and dump (drops comments)
          def strip_yaml(p, src):
              try:
                  import yaml
                  return yaml.safe_dump(yaml.safe_load(src), sort_keys=False)
              except Exception:
                  return src

          def strip_toml(p, src):
              try:
                  import tomllib, tomli_w
                  data = tomllib.loads(src)
                  return tomli_w.dumps(data)
              except Exception:
                  return src

          def strip_ini(p, src):
              import configparser, io
              cfg = configparser.ConfigParser()
              try:
                  cfg.read_string(src)
                  with io.StringIO() as buf:
                      cfg.write(buf, space_around_delimiters=False)
                      return buf.getvalue()
              except Exception:
                  return src

          def strip_web_files(paths):
              if not paths: return
              files_arg = json.dumps([str(p) for p in paths])
              js = r"""
              const fs = require('fs');
              const strip = require('strip-comments');
              const files = JSON.parse(process.argv[2]);
              for (const f of files) {
                try {
                  const src = fs.readFileSync(f, 'utf8');
                  let out;
                  if (f.endsWith('.css')) out = strip.css(src);
                  else if (f.endsWith('.html') || f.endsWith('.htm')) out = strip.html(src);
                  else out = strip(src);
                  fs.writeFileSync(f, out.endsWith('\n') ? out : out + '\n', 'utf8');
                } catch {}
              }
              """
              subprocess.run(["node", "-e", js, files_arg], check=True)

          web_exts = {".js",".jsx",".ts",".tsx",".css",".html",".htm"}
          py_exts  = {".py"}
          yaml_exts= {".yml",".yaml"}
          toml_exts= {".toml"}
          ini_exts = {".ini",".cfg"}
          sql_exts = {".sql"}
          hash_exts= {".sh",".bash",".zsh",".env",".dockerignore"}
          web_files = []

          for p in ROOT.rglob("*"):
              if not p.is_file(): continue
              if p.name.lower() == "dockerfile" or p.suffix.lower() == ".dockerfile":
                  src = read_utf8(p)
                  if src: write_utf8(p, strip_hash_lang(src))
                  continue
              ext = p.suffix.lower()
              src = read_utf8(p)
              if src is None: continue
              if ext in web_exts:
                  web_files.append(p)
              elif ext in py_exts:
                  write_utf8(p, strip_python(src))
              elif ext in yaml_exts:
                  write_utf8(p, strip_yaml(p, src))
              elif ext in toml_exts:
                  write_utf8(p, strip_toml(p, src))
              elif ext in ini_exts:
                  write_utf8(p, strip_ini(p, src))
              elif ext in sql_exts:
                  write_utf8(p, strip_sql(src))
              elif ext in hash_exts:
                  write_utf8(p, strip_hash_lang(src))

          strip_web_files(web_files)
          PY

      - name: (Optional) Upload clean artifact
        uses: actions/upload-artifact@v4
        with:
          name: clean-output
          path: clean

      - name: Prepare destination repo checkout (uses PAT secret)
        run: |
          rm -rf dest && mkdir -p dest
          cd dest
          git init
          git config user.name  "${GIT_AUTHOR_NAME}"
          git config user.email "${GIT_AUTHOR_EMAIL}"
          git remote add origin "https://x-access-token:${{ secrets.CLEAN_REPO_TOKEN }}@github.com/${{ env.DEST_OWNER }}/${{ env.DEST_REPO }}.git"
          git fetch origin "${DEST_DEFAULT_BRANCH}" || true
          git checkout -B "${DEST_DEFAULT_BRANCH}"

      - name: Replace destination tree with clean output and push
        run: |
          rsync -a --delete \
            --exclude "node_modules" \
            --exclude "package.json" \
            --exclude "package-lock.json" \
            clean/ dest/
          cd dest
          if [ -n "$(git status --porcelain)" ]; then
            git add -A
            git commit -m "chore: mirror with ALL comments removed from ${GITHUB_REPOSITORY}@${GITHUB_SHA}"
            git push origin "${DEST_DEFAULT_BRANCH}"
          else
            echo "No changes to push."
          fi
